{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance as gd\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_positions_2019 = pd.read_pickle(\"./data/[PSV]df_positions_2019_ver2.pkl\")\n",
    "\n",
    "df_vessel_daily_data = pd.read_pickle(\"./data/df_vessel_daily_2019_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_information = pd.read_csv(\"./data/Vessel_information.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data = df_positions_2019.loc[\n",
    "    (df_positions_2019['activity_label'].isin(['Standby', 'DP', 'Port', 'TransitCombine'])), \n",
    "    ['id', 'vessel_id', 'speed','new_position_received_time',\n",
    "     'prev_receive_time', 'prev_coord', 'curr_coord', 'mile_since','hour_since', \n",
    "     'speed_nm', 'fuel_consumption_average', 'activity_label', 'activity_label2',\n",
    "     'time_period', 'ref_date', 'transit_type', 'daily_vessel_id']].sort_values(by=['vessel_id', \n",
    "                                                                                    'new_position_received_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data['ref_date'] = pd.to_datetime(df_aggregate_data.ref_date, errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_aggregate_data = df_aggregate_data.groupby(by=['daily_vessel_id']).agg({'mile_since': 'sum',\n",
    "                                                                           'hour_since': 'sum',\n",
    "                                                                           'new_position_received_time': 'min',\n",
    "                                                                           'speed': ['max', 'mean'], \n",
    "                                                                           'speed_nm': ['max', 'median', 'mean'], \n",
    "                                                                           'fuel_consumption_average': ['max', 'mean'],\n",
    "                                                                           'curr_coord': ['first', 'last'],\n",
    "                                                                           'activity_label': 'first',\n",
    "                                                                           'activity_label2': 'first',\n",
    "                                                                           'transit_type': 'first'\n",
    "                                                                 }).reset_index(col_level=0)\n",
    "\n",
    "df_aggregate_data.columns = ['_'.join(col).strip() for col in df_aggregate_data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data['period_total_distance'] = df_aggregate_data.apply(lambda x: gd.distance(x['curr_coord_first'],\n",
    "                                                                                          x['curr_coord_last']\n",
    "                                                                                          ).nm, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data.loc[df_aggregate_data['period_total_distance'] == 0, 'period_total_distance'] = 0.00001\n",
    "df_aggregate_data['distance_ratio'] = df_aggregate_data.mile_since_sum/df_aggregate_data.period_total_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data.to_pickle(\"data/[PSV]df_aggregate_data_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data = pd.read_pickle(\"./data/[PSV]df_aggregate_data_1.pkl\")\n",
    "df_vessel_daily_data = pd.read_pickle(\"./data/df_vessel_daily_2019_complete.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['daily_vessel_id_', 'mile_since_sum', 'hour_since_sum',\n",
       "       'new_position_received_time_min', 'speed_max', 'speed_mean',\n",
       "       'speed_nm_max', 'speed_nm_median', 'speed_nm_mean',\n",
       "       'fuel_consumption_average_max', 'fuel_consumption_average_mean',\n",
       "       'curr_coord_first', 'curr_coord_last', 'activity_label_first',\n",
       "       'activity_label2_first', 'transit_type_first', 'period_total_distance',\n",
       "       'distance_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_label_first              120646\n",
       "transit_type_first                120646\n",
       "hour_since_sum                    120646\n",
       "mile_since_sum                    120646\n",
       "period_total_distance             120646\n",
       "distance_ratio                    120646\n",
       "fuel_consumption_average_max      120646\n",
       "fuel_consumption_average_mean     120646\n",
       "speed_nm_max                      120644\n",
       "speed_nm_median                   120644\n",
       "speed_nm_mean                     120644\n",
       "daily_vessel_id_                  120646\n",
       "new_position_received_time_min    120646\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate_data = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'].isin(['Standby', 'DP', 'Port', 'TransitCombine']))\n",
    "                                          &\n",
    "                                          (df_aggregate_data['new_position_received_time_min']<'2019-12-22') \n",
    "                                          , ['activity_label_first', 'transit_type_first',\n",
    "                                                                                                             'hour_since_sum',\n",
    "                                                                                                             'mile_since_sum',\n",
    "                                                                                                             'period_total_distance',\n",
    "                                                                                                             'distance_ratio',\n",
    "                                                                                                             'fuel_consumption_average_max', \n",
    "                                                                                                             'fuel_consumption_average_mean',\n",
    "                                                                                                             'speed_nm_max', 'speed_nm_median', \n",
    "                                                                                                             'speed_nm_mean',\n",
    "                                                                                                             'daily_vessel_id_',\n",
    "                                                                                                             'new_position_received_time_min'\n",
    "                                                                                                    ]]\n",
    "\n",
    "df_aggregate_data.loc[df_aggregate_data['transit_type_first'].isin(['Transit Max']), 'activity_label_first'] = df_aggregate_data['transit_type_first']\n",
    "# df_aggregate_data.activity_label_first.value_counts()\n",
    "df_aggregate_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_DP = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'DP'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.25)\n",
    "Q3_DP = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'DP'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.75)\n",
    "IQR_DP = Q3_DP - Q1_DP\n",
    "\n",
    "Q1_Port = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Port'), ['fuel_consumption_average_mean', 'period_total_distance']].quantile(0.25)\n",
    "Q3_Port = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Port'), ['fuel_consumption_average_mean', 'period_total_distance']].quantile(0.75)\n",
    "IQR_Port = Q3_Port - Q1_Port\n",
    "\n",
    "Q1_Standby = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Standby'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.25)\n",
    "Q3_Standby = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Standby'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.75)\n",
    "IQR_Standby = Q3_Standby - Q1_Standby\n",
    "\n",
    "# Q1_TransitEco = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Transit Eco'), ['fuel_consumption_average_mean', 'period_total_distance', 'speed_nm_mean', 'distance_ratio']].quantile(0.25)\n",
    "# Q3_TransitEco = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Transit Eco'), ['fuel_consumption_average_mean', 'period_total_distance', 'speed_nm_mean', 'distance_ratio']].quantile(0.75)\n",
    "# IQR_TransitEco = Q3_TransitEco - Q1_TransitEco\n",
    "\n",
    "Q1_Transit = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'TransitCombine'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.25)\n",
    "Q3_Transit = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'TransitCombine'), ['fuel_consumption_average_mean','distance_ratio']].quantile(0.75)\n",
    "IQR_Transit = Q3_Transit - Q1_Transit\n",
    "\n",
    "Q1_TransitMax = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Transit Max'), ['hour_since_sum', 'mile_since_sum','period_total_distance', 'distance_ratio','fuel_consumption_average_max', 'fuel_consumption_average_mean','speed_nm_max', 'speed_nm_median', 'speed_nm_mean']].quantile(0.25)\n",
    "Q3_TransitMax = df_aggregate_data.loc[(df_aggregate_data['activity_label_first'] == 'Transit Max'), ['hour_since_sum', 'mile_since_sum','period_total_distance', 'distance_ratio','fuel_consumption_average_max', 'fuel_consumption_average_mean','speed_nm_max', 'speed_nm_median', 'speed_nm_mean']].quantile(0.75)\n",
    "IQR_TransitMax = Q3_TransitMax - Q1_TransitMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data = df_aggregate_data[\n",
    "   ((df_aggregate_data['activity_label_first'] == 'DP') & (~((df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] < (Q1_DP - 1.5 * IQR_DP)) | (df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] > (Q3_DP + 1.5 * IQR_DP))).any(axis=1)))\n",
    "   |\n",
    "   ((df_aggregate_data['activity_label_first'] == 'Port') & (~((df_aggregate_data[['fuel_consumption_average_mean', 'period_total_distance']] < (Q1_Port - 1.5 * IQR_Port)) | (df_aggregate_data[['fuel_consumption_average_mean', 'period_total_distance']] > (Q3_Port + 1.5 * IQR_Port))).any(axis=1)))\n",
    "   |\n",
    "   ((df_aggregate_data['activity_label_first'] == 'Standby') & (~((df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] < (Q1_Standby - 1.5 * IQR_Standby)) | (df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] > (Q3_Standby + 1.5 * IQR_Standby))).any(axis=1)))\n",
    "#     |\n",
    "#     ((df_aggregate_data['activity_label_first'] == 'Transit Eco') & (~((df_aggregate_data < (Q1_TransitEco - 1.5 * IQR_TransitEco)) | (df_aggregate_data > (Q3_TransitEco + 1.5 * IQR_TransitEco))).any(axis=1)))\n",
    "    |\n",
    "    ((df_aggregate_data['activity_label_first'] == 'TransitCombine') & (~((df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] < (Q1_Transit - 1.5 * IQR_Transit)) | (df_aggregate_data[['fuel_consumption_average_mean','distance_ratio']] > (Q3_Transit + 1.5 * IQR_Transit))).any(axis=1)))\n",
    "    |\n",
    "    ((df_aggregate_data['activity_label_first'] == 'Transit Max') & (~((df_aggregate_data[['hour_since_sum', 'mile_since_sum','period_total_distance', 'distance_ratio','fuel_consumption_average_max', 'fuel_consumption_average_mean','speed_nm_max', 'speed_nm_median', 'speed_nm_mean']] < (Q1_TransitMax - 1.5 * IQR_TransitMax)) | (df_aggregate_data[['hour_since_sum', 'mile_since_sum','period_total_distance', 'distance_ratio','fuel_consumption_average_max', 'fuel_consumption_average_mean','speed_nm_max', 'speed_nm_median', 'speed_nm_mean']] > (Q3_TransitMax + 1.5 * IQR_TransitMax))).any(axis=1)))\n",
    "    \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransitCombine    28920\n",
       "DP                27430\n",
       "Standby           21106\n",
       "Port              19891\n",
       "Transit Max        2124\n",
       "Name: activity_label_first, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate_data['activity_label_first'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, ..., 3, 0, 3]),\n",
       " Index(['Port', 'TransitCombine', 'Standby', 'DP', 'Transit Max'], dtype='object'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggregate_data.activity_label_first.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate_data['activity_label_code'] = df_aggregate_data.activity_label_first.factorize()[0]\n",
    "\n",
    "#split train and test dataset\n",
    "# train_dataset2 = df_aggregate_data\n",
    "# test_dataset2 = df_aggregate_data.loc[(df_aggregate_data['new_position_received_time_min']>'2019-11-1')]\n",
    "\n",
    "# test_dataset2 = df_vessel_plot_AH_agg.loc[(df_vessel_plot_AH_agg['new_position_received_time_']>='2019-10-1')\n",
    "#                                   &\n",
    "#                                    (df_vessel_plot_AH_agg['new_position_received_time_']<'2019-12-1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_x = df_aggregate_data.loc[(df_aggregate_data['speed_nm_max'].isna()==False)\n",
    "                                        &\n",
    "                                        (df_aggregate_data['new_position_received_time_min']<'2019-12-22') \n",
    "                                        , \n",
    "                                     ['hour_since_sum', 'mile_since_sum',\n",
    "       'period_total_distance', 'distance_ratio',\n",
    "       'fuel_consumption_average_max', 'fuel_consumption_average_mean',\n",
    "       'speed_nm_max', 'speed_nm_median', 'speed_nm_mean'\n",
    "                                     ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_y = df_aggregate_data.loc[(df_aggregate_data['speed_nm_max'].isna()==False)\n",
    "                                        &\n",
    "                                        (df_aggregate_data['new_position_received_time_min']<'2019-12-22')\n",
    "                                        , 'activity_label_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataset_x = df_aggregate_data.loc[(df_aggregate_data['speed_nm_max'].isna()==False)\n",
    "                                           &\n",
    "                                           (df_aggregate_data['new_position_received_time_min']>='2019-12-22') , \n",
    "                                     ['hour_since_sum', 'mile_since_sum',\n",
    "       'period_total_distance', 'distance_ratio',\n",
    "       'fuel_consumption_average_max', 'fuel_consumption_average_mean',\n",
    "       'speed_nm_max', 'speed_nm_median', 'speed_nm_mean'\n",
    "                                     ]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataset_y = df_aggregate_data.loc[(df_aggregate_data['speed_nm_max'].isna()==False)\n",
    "                                           &\n",
    "                                           (df_aggregate_data['new_position_received_time_min']>='2019-12-22') \n",
    "                                           , 'activity_label_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "\n",
    "# split the training data to train and validate\n",
    "train_x, validate_x, train_y, validate_y = train_test_split(train_dataset_x, train_dataset_y, test_size = 0.25, random_state = 42, stratify=train_dataset_y)\n",
    "\n",
    "# # split the SCALED training data to train and validate \n",
    "# # train_x_scaled, validate_x_scaled, train_y_scaled, validate_y_scaled = train_test_split(X_scaled, train_dataset_y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# # Variable X then fitted to the scaler\n",
    "scaler = RobustScaler().fit(train_x)\n",
    "# # Then Transform the X into array X_scaled, this variable later will be the parameter for model\n",
    "train_X_scaled = scaler.transform(train_x)\n",
    "val_X_scaled = scaler.transform(validate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9835528299989946\n"
     ]
    }
   ],
   "source": [
    "randomforrest_clf = RandomForestClassifier(max_depth=50, max_features=6, min_samples_leaf=2,\n",
    "                       min_samples_split=4, n_estimators=500)\n",
    "\n",
    "randomforrest_clf.fit(train_dataset_x, train_dataset_y)\n",
    "# randomforrest_clf.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(randomforrest_clf.score(train_dataset_x, train_dataset_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = randomforrest_clf.predict(train_dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/[PSV]random_forest_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d14e2882a40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# serialized the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[PSV]random_forest_model.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomforrest_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/[PSV]random_forest_model.pkl'"
     ]
    }
   ],
   "source": [
    "# serialized the model\n",
    "file_name = '[PSV]random_forest_model.pkl'\n",
    "pickle.dump(randomforrest_clf, open('model/'+file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999899467176033\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=30, algorithm='brute', weights='distance', p=1)\n",
    "knn_clf.fit(train_dataset_x, train_dataset_y)\n",
    "knn_training_score = knn_clf.score(train_dataset_x, train_dataset_y)\n",
    "\n",
    "print(knn_training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014979390771086\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(gamma=2, C=1)\n",
    "svm_clf.fit(train_dataset_x, train_dataset_y)\n",
    "svm_training_score = svm_clf.score(train_dataset_x, train_dataset_y)\n",
    "\n",
    "print(svm_training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efs/anaconda3/envs/vessel_analysis_2/lib/python3.6/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8721121946315472\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "class_weights = list([ 1.00020111, 0.68789765, 0.94257557, 0.72526431, 9.36629002])\n",
    "\n",
    "w_array = np.ones(train_dataset_y.shape[0])\n",
    "for i, val in enumerate(train_dataset_y):\n",
    "    w_array[i] = class_weights[val-1]\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "xgb_clf.fit(train_dataset_x, train_dataset_y)\n",
    "\n",
    "# make predictions for test data\n",
    "xgb_predictions = xgb_clf.predict(train_dataset_x)\n",
    "# xgb_predictions = xgb_clf.predict(val_X_scaled)\n",
    "\n",
    "# evaluate predictions\n",
    "xgb_training_score = xgb_clf.score(train_dataset_x, train_dataset_y)\n",
    "# xgb_training_score = xgb_clf.score(val_X_scaled, validate_y)\n",
    "print(xgb_training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialized the model\n",
    "file_name2 = '[PSV]xg_boost_model.pkl'\n",
    "pickle.dump(xgb_clf, open('model/'+file_name2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:20] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9351864883884589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# List of models to vote\n",
    "four_models_voting_clf = VotingClassifier(estimators=[('xgboost', xgb_clf), \n",
    "                                                      ('randomforest', randomforrest_clf), \n",
    "                                                      ('knearest', knn_clf), \n",
    "                                                      ('svm', svm_clf)],\n",
    "                                          voting='hard', weights=[1.5,1.3,1,1])\n",
    "\n",
    "four_models_voting_clf.fit(train_dataset_x, train_dataset_y) \n",
    "print(four_models_voting_clf.score(train_dataset_x, train_dataset_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialized the ensemble model\n",
    "file_name_ense = '[PSV]ensemble_model3.pkl'\n",
    "pickle.dump(four_models_voting_clf, open('model/'+file_name_ense, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# confusion_matrix(validate_y, predictions)\n",
    "cm_1 = plot_confusion_matrix(randomforrest_clf, val_X_scaled, validate_y, \n",
    "                      display_labels=['Standby', 'DP', 'Port', 'TransitCombine', 'Towing', 'AH',\n",
    "        'Transit Max'], \n",
    "                      cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "\n",
    "cm_1.ax_.set_title('Confusion Matrix')\n",
    "\n",
    "print(cm_1.confusion_matrix)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:0.9870661385089555\n",
      "Recall Score:0.9479174148854426\n",
      "F1 Score:0.965056906600313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision_macro = precision_score(train_dataset_y, rf_predictions, average='macro')\n",
    "precision_weighted = precision_score(train_dataset_y, rf_predictions, average='weighted')\n",
    "\n",
    "recall_macro = recall_score(train_dataset_y, rf_predictions, average='macro')\n",
    "recall_weighted = recall_score(train_dataset_y, rf_predictions, average='weighted')\n",
    "\n",
    "f1_score = f1_score(train_dataset_y, rf_predictions, average='macro')\n",
    "\n",
    "print('Precision Score:' + str(precision_macro))\n",
    "print('Recall Score:' + str(recall_macro))\n",
    "print('F1 Score:' + str(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
